import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import time
import logging
import json
import os
from uuid import uuid4
import re
from datetime import datetime
from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.utils import get_column_letter


class AdvancedVapeScraper:
    def __init__(self, job_id=None):
        self.job_id = job_id or str(uuid4())
        self.driver = None
        self.products_data = []
        self.is_running = False
        self.current_site = ""
        self.site_configs = {}
        self.setup_logging()
        self.setup_driver()
        self.setup_site_configs()
        
        os.makedirs('tmp_jobs', exist_ok=True)
    
    def setup_driver(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª WebDriver"""
        try:
            options = webdriver.ChromeOptions()
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            # options.add_argument('--headless')  # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
            
            self.driver = webdriver.Chrome(options=options)
            self.driver.implicitly_wait(5)
            
            logging.info("âœ… Ø¯Ø±Ø§ÛŒÙˆØ± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ±: {e}")
            raise
    
    def setup_site_configs(self):
        """Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ 7 Ø³Ø§ÛŒØª Ù‡Ø¯Ù"""
        self.site_configs = {
            'dokhanmarket': {
                #Ø¯Ø®Ø§Ù† Ù…Ø§Ø±Ú©Øª
                'name': 'Dokhan Market',
                'base_urls': ['https://dokhanmarket3.com', 'http://dokhanmarket3.com'],
                'category_selectors': [
                    'a[href*="category"]',
                    '.menu-link',
                    'nav a',
                    '.product-category a'
                ],
                'product_selectors': [
                    '.product-card',
                    '.product',
                    '.product-item',
                    '.goods-item'
                ],
                'name_selectors': [
                    '.product-card_link',
                    '.product-title',
                    'h3',
                    'h2',
                    '.product-name'
                ],
                'price_selectors': [
                    '.product-card_price',
                    '.price',
                    '.woocommerce-Price-amount',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    'a[href*="page="]',
                    '.next',
                    '.pagination-next',
                    'a.next'
                ],
                'next_text': ['Ø¨Ø¹Ø¯ÛŒ', 'next', 'â†’'],
                'category_keywords': ['category', 'cat', 'product-category', 'shop']
            },
            'tajvape': {
                #ØªØ§Ø¬ ÙˆÛŒÙ¾
                'name': 'Tajvape',
                'base_urls': ['https://tajvape12.com', 'http://tajvape12.com'],
                'category_selectors': [
                    '.dropdown-toggle.menu-link',
                    '.menu-link',
                    'nav a',
                    '.product-category a',
                    'a[href*="product-category"]'
                ],
                'product_selectors': [
                    'ul.products columns-4',
                    'li.col-md-3 col-6 mini-product-con type-product',
                    '.product-link',
                    '.col-md-3 col-6 mini-product-con type-product',
                    
                    'div.woocommerce shadow-box prblur mini-product product-112542 prod-variable',
                    '.product',
                    '.product-item',
                    '.woocommerce-product',
                    'li.product'
                ],
                'name_selectors': [
                    '.product-title',
                    'h2',
                    'h3',
                    '.woocommerce-loop-product__title'
                ],
                'price_selectors': [
                    '.woocommerce-Price-amount',
                    '.price',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    '.next.page-numbers',
                    '.pagination a',
                    'a.next',
                    'a[href*="page/"]'
                ],
                'next_text': ['â†’', 'next', 'Ø¨Ø¹Ø¯ÛŒ'],
                'category_keywords': ['product-category', 'category', 'e-juice', 'vape']
            },
            'vapoursdaily': {
                #ÙˆÛŒÙ¾Ø±Ø² Ø¯ÛŒÙ„ÛŒ
                'name': 'Vapours Daily',
                'base_urls': ['https://vapoursdaily14.com', 'http://vapoursdaily14.com'],
                'category_selectors': [
                    '.menu-item a',
                    'nav a',
                    '.product-category a',
                    'a[href*="category"]'
                ],
                'product_selectors': [
                    '.product',
                    '.product-item',
                    '.woocommerce-product',
                    '.goods-item'
                ],
                'name_selectors': [
                    '.product-tittle',
                    'h3',
                    'h2',
                    '.product-name'
                ],
                'price_selectors': [
                    '.woocommerce-Price-amount',
                    '.price',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    '.next.page-numbers',
                    '.pagination a',
                    'a.next'
                ],
                'next_text': ['â†', 'next', 'Ø¨Ø¹Ø¯ÛŒ'],
                'category_keywords': ['product-category', 'category', 'vape']
            },
            'smokcenter': {
                #Ø§Ø³Ù…ÙˆÚ© Ø³Ù†ØªØ±
                'name': 'Smok Center',
                'base_urls': ['https://smokcenter16.com', 'http://smokcenter16.com'],
                'category_selectors': [
                    'spen.elementor-icon-list-icon',
                    'spen.elementor-icon-list-text',
                    'li.elementor-icon-list-item',
                    'div.elementor-icon-wrapper',
                    '.elementor-icon',
                    '.e-n-tab-title-text',
                    'e-n-tab-title-3544064532.',
                    '.e-n-tab-title',
                    
                    '.wd-nav-products-cats a',
                    'nav a',
                    '.category-item a',
                    'a[href*="category"]'
                ],
                'product_selectors': [
                    '.product',
                    '.product-item',
                    '.wd-entities-title',
                    '.goods-item'
                ],
                'name_selectors': [
                    '.wd-entities-title',
                    'h3',
                    'h2',
                    '.product-title'
                ],
                'price_selectors': [
                    '.woocommerce-Price-amount',
                    '.price',
                    'ins .amount',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    '.load-more-label',
                    '.next',
                    '.pagination a',
                    'a[href*="page"]'
                ],
                'next_text': ['Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¨ÛŒØ´ØªØ± Ù…Ø­ØµÙˆÙ„Ø§Øª', 'next', 'Ø¨Ø¹Ø¯ÛŒ'],
                'category_keywords': ['shop', 'category', 'ejuice']
            },
            'digizima': {
                #Ø¯ÛŒØ¬ÛŒ Ø²ÛŒÙ…Ø§
                'name': 'Digi Zima',
                'base_urls': ['https://digizima19.com', 'http://digizima19.com'],
                'category_selectors': [
                    '.menu-item a',
                    'nav a',
                    '.product-category a',
                    'a[href*="category"]'
                ],
                'product_selectors': [
                    '.product',
                    '.product-item',
                    '.wd-entities-title',
                    '.goods-item'
                ],
                'name_selectors': [
                    '.wd-entities-title',
                    'h3',
                    'h2',
                    '.product-name'
                ],
                'price_selectors': [
                    '.woocommerce-Price-amount',
                    '.price',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    '.next.page-numbers',
                    '.pagination a',
                    'a.next'
                ],
                'next_text': ['â†’', 'next', 'Ø¨Ø¹Ø¯ÛŒ'],
                'category_keywords': ['product-category', 'category', 'vape']
            },
            'digighelioon': {
                #Ø¯ÛŒØ¬ÛŒ Ù‚Ù„ÛŒÙˆÙ†
                'name': 'Digi Ghelioon',
                'base_urls': ['https://digighelioon.com', 'http://digighelioon.com'],
                'category_selectors': [
                    'a.active',
                    '.menu-item a',
                    'nav a',
                    'a[href*="hookah-components"]',
                    'a[href*="category"]'
                ],
                'product_selectors': [
                    '.product',
                    '.product-item',
                    '.product-card',
                    '.goods-item'
                ],
                'name_selectors': [
                    '.product-name',
                    'h3',
                    'h2',
                    '.product-title'
                ],
                'price_selectors': [
                    '.woocommerce-Price-amount',
                    '.price',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    '.next',
                    '.pagination a',
                    'a[href*="page"]'
                ],
                'next_text': ['Ø¨Ø¹Ø¯ÛŒ', 'next', 'â†’'],
                'category_keywords': ['product-category', 'category', 'hookah-components']
            },
            'vape60': {
                #ÙˆÛŒÙ¾ 60
                'name': 'Vape 60',
                'base_urls': ['https://vape60shop22.com', 'http://vape60shop22.com'],
                'category_selectors': [
                    '.menu-item a',
                    'nav a',
                    '.product-category a',
                    'a[href*="category"]'
                ],
                'product_selectors': [
                    '.product',
                    '.product-item',
                    '.woocommerce-product',
                    '.goods-item'
                ],
                'name_selectors': [
                    '.woocommerce-loop-product__title',
                    'h2',
                    'h3',
                    'b'
                ],
                'price_selectors': [
                    '.woocommerce-Price-amount',
                    '.price',
                    '.amount',
                    'bdi'
                ],
                'pagination_selectors': [
                    '.next.page-numbers',
                    '.pagination a',
                    'a.next'
                ],
                'next_text': ['â†', 'next', 'Ø¨Ø¹Ø¯ÛŒ'],
                'category_keywords': ['product-category', 'category', 'podsystem']
            }
        }
    
    def identify_site(self, url):
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø§ÛŒØª Ø¨Ø± Ø§Ø³Ø§Ø³ URL Ùˆ Ù…Ø­ØªÙˆØ§"""
        logging.info(f"ğŸ” Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø§ÛŒØª Ø¨Ø±Ø§ÛŒ: {url}")
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ URL
        for site_id, config in self.site_configs.items():
            for base_url in config['base_urls']:
                if base_url in url:
                    logging.info(f"âœ… Ø³Ø§ÛŒØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {config['name']}")
                    return site_id
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡
        try:
            self.driver.get(url)
            time.sleep(3)
            page_source = self.driver.page_source
            title = self.driver.title.lower()
            
            if 'dokhan' in title or 'Ø¯Ø®Ø§Ù†' in page_source:
                return 'dokhanmarket'
            elif 'tajvape' in title or 'tajvape' in page_source:
                return 'tajvape'
            elif 'vapoursdaily' in title or 'vapours' in page_source:
                return 'vapoursdaily'
            elif 'smokcenter' in title or 'smok' in page_source:
                return 'smokcenter'
            elif 'digizima' in title or 'Ø²ÛŒÙ…Ø§' in page_source:
                return 'digizima'
            elif 'digighelioon' in title or 'Ù‚Ù„ÛŒÙˆÙ†' in page_source:
                return 'digighelioon'
            elif 'vape60' in title or 'vape60' in page_source:
                return 'vape60'
            else:
                logging.warning("âš ï¸ Ø³Ø§ÛŒØª Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ")
                return 'tajvape'
                
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø§ÛŒØª: {e}")
            return 'tajvape'
    
    def setup_logging(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ… Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'tmp_jobs/{self.job_id}_log.txt', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def update_status(self, message, page=1, total_pages=1, products_found=0, current_site=""):
        """Ø¢Ù¾Ø¯ÛŒØª ÙˆØ¶Ø¹ÛŒØª"""
        status = {
            'job_id': self.job_id,
            'status': message,
            'page': page,
            'total_pages': total_pages,
            'products_count': products_found,
            'total_products': len(self.products_data),
            'current_site': current_site,
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            with open(f'tmp_jobs/{self.job_id}_status.json', 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Error saving status: {e}")
    
    def get_categories(self, url, site_id):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØª Ù…Ø´Ø®Øµ"""
        self.update_status("Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§", current_site=site_id)
        logging.info(f"ğŸ” Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø²: {url} Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØª {site_id}")
        
        try:
            self.driver.get(url)
            time.sleep(4)
            
            categories = []
            config = self.site_configs[site_id]
            seen_urls = set()
            
            # Ø±ÙˆØ´ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø®ØµÙˆØµ Ø³Ø§ÛŒØª
            for selector in config['category_selectors']:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        logging.info(f"ğŸ¯ {len(elements)} Ø§Ù„Ù…Ù†Øª Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ± {selector}")
                        
                        for element in elements:
                            try:
                                href = element.get_attribute('href')
                                text = element.text.strip()
                                
                                if href and href not in seen_urls and text and 2 < len(text) < 100:
                                    if self.is_valid_category(href, text, site_id):
                                        categories.append({
                                            'name': text,
                                            'url': href,
                                            'site': site_id,
                                            'site_name': config['name']
                                        })
                                        seen_urls.add(href)
                                        logging.info(f"ğŸ“ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {text}")
                            except Exception as e:
                                logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù„Ù…Ù†Øª: {e}")
                                continue
                        
                        if len(categories) >= 10:
                            break
                except Exception as e:
                    logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ø³Ù„Ú©ØªÙˆØ± {selector}: {e}")
                    continue
            
            # Ø±ÙˆØ´ 2: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¯Ø³ØªÛŒ Ø¯Ø± Ù…Ù†ÙˆÙ‡Ø§
            if len(categories) < 3:
                categories.extend(self.find_categories_manually(site_id))
            
            # Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ
            unique_categories = []
            seen_names = set()
            for cat in categories:
                if cat['name'] not in seen_names:
                    unique_categories.append(cat)
                    seen_names.add(cat['name'])
            
            if not unique_categories:
                unique_categories.append({
                    'name': 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ØµÙ„ÛŒ',
                    'url': url,
                    'site': site_id,
                    'site_name': config['name']
                })
            
            logging.info(f"ğŸ“‚ {len(unique_categories)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ {site_id} ÛŒØ§ÙØª Ø´Ø¯")
            return unique_categories[:12]  # Ø­Ø¯Ø§Ú©Ø«Ø± 12 Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {site_id}: {e}")
            return [{
                'name': 'Ù…Ø­ØµÙˆÙ„Ø§Øª',
                'url': url,
                'site': site_id,
                'site_name': self.site_configs[site_id]['name']
            }]
    
    def find_categories_manually(self, site_id):
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¯Ø³ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§"""
        categories = []
        try:
            # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…Ù†ÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            menu_selectors = ['nav', '.menu', '.navigation', '.main-menu', '.categories']
            
            for selector in menu_selectors:
                try:
                    menus = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for menu in menus:
                        links = menu.find_elements(By.TAG_NAME, 'a')
                        for link in links:
                            try:
                                href = link.get_attribute('href')
                                text = link.text.strip()
                                if href and text and len(text) > 2 and self.is_valid_category(href, text, site_id):
                                    categories.append({
                                        'name': text,
                                        'url': href,
                                        'site': site_id,
                                        'site_name': self.site_configs[site_id]['name']
                                    })
                            except:
                                continue
                except:
                    continue
        except:
            pass
        
        return categories
    
    def is_valid_category(self, href, text, site_id):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ"""
        if not href or not text:
            return False
        
        text_lower = text.lower()
        href_lower = href.lower()
        
        # Ú©Ù„Ù…Ø§Øª Ù…Ù…Ù†ÙˆØ¹Ù‡
        exclude_words = [
            'home', 'main', 'ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ', 'contact', 'ØªÙ…Ø§Ø³', 'about', 'Ø¯Ø±Ø¨Ø§Ø±Ù‡',
            'blog', 'Ø¨Ù„Ø§Ú¯', 'account', 'Ø­Ø³Ø§Ø¨', 'cart', 'Ø³Ø¨Ø¯', 'checkout', 'Ù¾Ø±Ø¯Ø§Ø®Øª',
            'search', 'Ø¬Ø³ØªØ¬Ùˆ', 'login', 'ÙˆØ±ÙˆØ¯', 'register', 'Ø«Ø¨Øª Ù†Ø§Ù…','Ø§Ø³Ù…ÙˆÚ© Ø³Ù†ØªØ± TV'
        ]
        
        if any(word in text_lower for word in exclude_words):
            return False
        
        if any(word in href_lower for word in exclude_words):
            return False
        
        # ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ Ù‡Ø± Ø³Ø§ÛŒØª
        config = self.site_configs[site_id]
        if any(keyword in href_lower for keyword in config['category_keywords']):
            return True
        
        # ÙÛŒÙ„ØªØ± Ø¹Ù…ÙˆÙ…ÛŒ
        category_indicators = ['category', 'cat', 'product', 'shop', 'Ù…Ø­ØµÙˆÙ„', 'Ø¯Ø³ØªÙ‡']
        if any(indicator in href_lower for indicator in category_indicators):
            return True
        
        return len(text) > 2 and len(text) < 50
    
    def scrape_category_pages(self, category_url, category_name, site_id):
        """Ø§Ø³Ú©Ø±Ù¾ ØªÙ…Ø§Ù… ØµÙØ­Ø§Øª ÛŒÚ© Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ - **Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ú©Ù„ÛŒÚ©**"""
        logging.info(f"ğŸ”„ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±Ù¾ Ø¹Ù…ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ: {category_name}")
        
        all_products = []
        current_page = 1
        max_pages = 50
        consecutive_empty_pages = 0
        max_consecutive_empty = 1
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡ Ø§ÙˆÙ„
        self.driver.get(category_url)
        time.sleep(3)
        
        while current_page <= max_pages and self.is_running and consecutive_empty_pages < max_consecutive_empty:
            logging.info(f"ğŸ“„ ØµÙØ­Ù‡ {current_page} Ø§Ø² {category_name}")
            self.update_status(f"ØµÙØ­Ù‡ {current_page} Ø§Ø² {category_name}", current_page, max_pages, len(all_products), site_id)
            
            try:
                # Ø§Ø³Ú©Ø±Ù¾ Ù…Ø­ØµÙˆÙ„Ø§Øª ØµÙØ­Ù‡ ÙØ¹Ù„ÛŒ
                page_products = self.scrape_products_from_page(category_name, site_id)
                
                if page_products:
                    # ÙÛŒÙ„ØªØ± Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
                    new_products = []
                    for product in page_products:
                        if not any(p['name'] == product['name'] and p['price'] == product['price'] 
                                for p in all_products):
                            new_products.append(product)
                    
                    if new_products:
                        all_products.extend(new_products)
                        logging.info(f"âœ… {len(new_products)} Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ Ø§Ø² ØµÙØ­Ù‡ {current_page}")
                        consecutive_empty_pages = 0  # Ø±ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡
                    else:
                        logging.info(f"ğŸ”„ Ù‡Ù…Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒØŒ ØµÙØ­Ù‡ {current_page}")
                        consecutive_empty_pages += 1
                else:
                    logging.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ Ø¯Ø± ØµÙØ­Ù‡ {current_page}")
                    consecutive_empty_pages += 1
                
                # Ø§Ú¯Ø± Û² ØµÙØ­Ù‡ Ù¾Ø´Øª Ø³Ø± Ù‡Ù… Ø®Ø§Ù„ÛŒ/ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯ØŒ ØªÙˆÙ‚Ù Ú©Ù†
                if consecutive_empty_pages >= max_consecutive_empty:
                    logging.info(f"ğŸš« {max_consecutive_empty} ØµÙØ­Ù‡ Ù¾Ø´Øª Ø³Ø± Ù‡Ù… Ø®Ø§Ù„ÛŒ - ØªÙˆÙ‚Ù")
                    break
                
                # Ø³Ø¹ÛŒ Ú©Ù† Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø±ÛŒ
                if current_page < max_pages:
                    if self.has_next_page_improved(site_id):
                        if self.click_next_page(site_id):
                            current_page += 1
                            time.sleep(2)
                        else:
                            # Ø§Ú¯Ø± Ù†ØªÙˆØ§Ù†Ø³Øª Ú©Ù„ÛŒÚ© Ú©Ù†Ù‡ØŒ Ø¨Ø§ URL Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø±Ùˆ
                            logging.info("ğŸ”„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² URL Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯")
                            next_url = self.get_page_url(category_url, current_page + 1, site_id)
                            self.driver.get(next_url)
                            time.sleep(3)
                            current_page += 1
                    else:
                        logging.info("ğŸ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ø§ØªÙ…Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ")
                        break
                else:
                    logging.info("ğŸ Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± ØµÙØ­Ø§Øª Ù…Ø¬Ø§Ø² Ø±Ø³ÛŒØ¯ÛŒÙ…")
                    break
                    
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØµÙØ­Ù‡ {current_page}: {e}")
                consecutive_empty_pages += 1
                
                # Ø³Ø¹ÛŒ Ú©Ù† Ø¨Ø§ URL Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø±ÛŒ
                try:
                    next_url = self.get_page_url(category_url, current_page + 1, site_id)
                    self.driver.get(next_url)
                    time.sleep(3)
                    current_page += 1
                except:
                    break
        
        logging.info(f"ğŸ‰ Ø§ØªÙ…Ø§Ù… {category_name}: {len(all_products)} Ù…Ø­ØµÙˆÙ„ Ø§Ø² {current_page} ØµÙØ­Ù‡")
        return all_products
                
    def get_page_url(self, base_url, page_number, site_id):
        """Ø³Ø§Ø®Øª URL ØµÙØ­Ù‡ - **Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØªÙ…Ø§Ù… ÙØ±Ù…Øªâ€ŒÙ‡Ø§**"""
        if page_number == 1:
            return base_url
            
        # Ø­Ø°Ù Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        base_clean = re.sub(r'[?&](page|paged)=\d+', '', base_url)
        base_clean = re.sub(r'/page/\d+', '', base_clean)
        base_clean = re.sub(r'/product-page/\d+', '', base_clean)
            
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø³Ø§ÛŒØª
        if site_id in ['tajvape', 'vapoursdaily', 'digizima']:
            # ÙØ±Ù…Øª: /page/2/
            return f"{base_clean}/page/{page_number}/"
        elif site_id in ['smokcenter', 'vape60']:
            # ÙØ±Ù…Øª: ?page=2
            separator = '?' if '?' not in base_clean else '&'
            return f"{base_clean}{separator}page={page_number}"
        elif site_id in ['dokhanmarket', 'digighelioon']:
                # ÙØ±Ù…Øª: /product-page/2/
            return f"{base_clean}/product-page/{page_number}/"
        else:
                # ÙØ±Ù…Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            separator = '?' if '?' not in base_clean else '&'
            return f"{base_clean}{separator}page={page_number}"
        
    def has_next_page_improved(self, site_id):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ - **Ù†Ø³Ø®Ù‡ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡**"""
        config = self.site_configs[site_id]
        current_url = self.driver.current_url
        
        logging.info(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø±Ø§ÛŒ {config['name']}")
        
        # Ø±ÙˆØ´ 1: Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ "Ø¨Ø¹Ø¯ÛŒ" Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        next_selectors = [
            'a.next', '.next', '.pagination-next', 
            '.page-numbers.next', '.next.page-numbers',
            'a[rel="next"]', '.next-page', '.pagination .next',
            '.woocommerce-pagination .next', '.nav-next',
            'a:contains("Ø¨Ø¹Ø¯ÛŒ")', 'a:contains("next")',
            'button.next', '.load-more', '.pagination-next a'
        ]
        
        for selector in next_selectors:
            try:
                next_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in next_elements:
                    try:
                        if element.is_displayed() and element.is_enabled():
                            text = element.text.lower().strip()
                            href = element.get_attribute('href') or ''
                            
                            # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯
                            next_keywords = ['next', 'Ø¨Ø¹Ø¯ÛŒ', 'â†’', 'Â»', '>', 'load more', 'more']
                            prev_keywords = ['Ù‚Ø¨Ù„ÛŒ', 'Ù‚Ø¨Ù„', 'â†', 'Â«', '<', 'previous']
                            
                            if (any(keyword in text for keyword in next_keywords) and 
                                not any(keyword in text for keyword in prev_keywords)):
                                logging.info(f"ğŸ¯ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯ Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±: {selector}")
                                return True
                    except:
                        continue
            except:
                continue
        
        # Ø±ÙˆØ´ 2: Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ú©Ù„ ØµÙØ­Ù‡ Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        try:
            # ØªÙ…Ø§Ù… Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ù…Ú©Ù† Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
            all_links = self.driver.find_elements(By.CSS_SELECTOR, 
                'a[href*="page"], a[href*="paged"], [class*="page"], [class*="pagination"] a, .page-numbers a, .pagination a, .page-links a')
            
            current_page = self.get_current_page_number(current_url)
            
            for link in all_links:
                try:
                    if not link.is_displayed():
                        continue
                        
                    link_text = link.text.strip()
                    href = link.get_attribute('href')
                    
                    if not href:
                        continue
                    
                    # Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø§Ø´Ø¯
                    if link_text.isdigit():
                        link_page = int(link_text)
                        if link_page == current_page + 1:
                            logging.info(f"ğŸ”¢ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯: ØµÙØ­Ù‡ {link_page}")
                            return True
                    
                    # Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ø´Ø§Ù…Ù„ Ú©Ù„Ù…Ø§Øª ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø§Ø´Ø¯
                    text_lower = link_text.lower()
                    if any(word in text_lower for word in ['next', 'Ø¨Ø¹Ø¯ÛŒ', 'â†’', 'Â»', '>']):
                        if not any(word in text_lower for word in ['Ù‚Ø¨Ù„ÛŒ', 'Ù‚Ø¨Ù„', 'â†']):
                            logging.info(f"ğŸ“– ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø§ Ù…ØªÙ†: {link_text}")
                            return True
                            
                except:
                    continue
        except Exception as e:
            logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§: {e}")
        
        # Ø±ÙˆØ´ 3: Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ XPath Ø¨Ø±Ø§ÛŒ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ
        try:
            next_texts = ['Ø¨Ø¹Ø¯ÛŒ', 'next', 'â†’', 'Â»', '>', 'Load more', 'More products']
            for text in next_texts:
                try:
                    elements = self.driver.find_elements(By.XPATH, f"//*[contains(text(), '{text}')]")
                    for element in elements:
                        try:
                            if element.is_displayed() and element.is_enabled():
                                # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù‡ Ø§Ù„Ù…Ù†Øª ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø§Ø³Øª
                                parent = element.find_element(By.XPATH, './..')
                                if parent.tag_name == 'a' or parent.get_attribute('onclick'):
                                    logging.info(f"ğŸ” ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø§ XPath: {text}")
                                    return True
                        except:
                            continue
                except:
                    continue
        except Exception as e:
            logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ XPath: {e}")
        
        # Ø±ÙˆØ´ 4: Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ± Ø¯Ø± URL Ø¨Ø¹Ø¯ Ø§Ø² Ú©Ù„ÛŒÚ© (Ø¨Ø±Ø§ÛŒ Load More)
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§Ù„Ù…Ù†Øªâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Load More Ø¨Ø§Ø´Ù†Ø¯
            buttons = self.driver.find_elements(By.CSS_SELECTOR, 
                'button, [onclick], [class*="load"], [class*="more"]')
            
            for button in buttons:
                try:
                    if button.is_displayed() and button.is_enabled():
                        text = button.text.lower()
                        if any(word in text for word in ['more', 'load', 'Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ', 'Ø¨ÛŒØ´ØªØ±']):
                            logging.info(f"ğŸ”„ Ø¯Ú©Ù…Ù‡ Load More Ù¾ÛŒØ¯Ø§ Ø´Ø¯: {text}")
                            return True
                except:
                    continue
        except:
            pass
        
        logging.info("âŒ Ù‡ÛŒÚ† ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return False
    
    def click_next_page(self, site_id):
        """Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ - **ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯**"""
        config = self.site_configs[site_id]
        current_url = self.driver.current_url
        
        logging.info("ğŸ–±ï¸ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯...")
        
        # Ø±ÙˆØ´ 1: Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ "Ø¨Ø¹Ø¯ÛŒ" Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        next_selectors = [
            'a.next', '.next', '.pagination-next', 
            '.page-numbers.next', '.next.page-numbers',
            'a[rel="next"]', '.next-page', '.pagination .next',
            '.woocommerce-pagination .next', '.nav-next'
        ]
        
        for selector in next_selectors:
            try:
                next_buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for button in next_buttons:
                    try:
                        if button.is_displayed() and button.is_enabled():
                            logging.info(f"âœ… Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±: {selector}")
                            self.driver.execute_script("arguments[0].click();", button)
                            time.sleep(3)
                            return True
                    except Exception as e:
                        logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ú©Ù„ÛŒÚ© Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ± {selector}: {e}")
                        continue
            except Exception as e:
                logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø³Ù„Ú©ØªÙˆØ± {selector}: {e}")
                continue
        
        # Ø±ÙˆØ´ 2: Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ø§Øª Ø¨Ø¹Ø¯ÛŒ
        try:
            current_page = self.get_current_page_number(current_url)
            page_links = self.driver.find_elements(By.CSS_SELECTOR, 
                '.page-numbers a, .pagination a, a.page-numbers, .page-links a')
            
            for link in page_links:
                try:
                    if link.is_displayed() and link.is_enabled():
                        link_text = link.text.strip()
                        if link_text.isdigit():
                            link_page = int(link_text)
                            if link_page == current_page + 1:
                                logging.info(f"ğŸ”¢ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ ØµÙØ­Ù‡ {link_page}")
                                self.driver.execute_script("arguments[0].click();", link)
                                time.sleep(3)
                                return True
                except:
                    continue
        except Exception as e:
            logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ø§Øª: {e}")
        
        # Ø±ÙˆØ´ 3: Ú©Ù„ÛŒÚ© Ø¨Ø§ XPath Ø±ÙˆÛŒ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ "Ø¨Ø¹Ø¯ÛŒ"
        try:
            next_texts = ['Ø¨Ø¹Ø¯ÛŒ', 'next', 'â†’', 'Â»', '>']
            for text in next_texts:
                try:
                    elements = self.driver.find_elements(By.XPATH, f"//*[contains(text(), '{text}')]")
                    for element in elements:
                        try:
                            if element.is_displayed() and element.is_enabled():
                                # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù‡ Ø§Ù„Ù…Ù†Øª ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ø§Ø³Øª
                                element_text = element.text.lower()
                                if not any(word in element_text for word in ['Ù‚Ø¨Ù„ÛŒ', 'Ù‚Ø¨Ù„', 'â†', 'Â«']):
                                    logging.info(f"ğŸ“– Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ: {text}")
                                    self.driver.execute_script("arguments[0].click();", element)
                                    time.sleep(3)
                                    return True
                        except:
                            continue
                except:
                    continue
        except Exception as e:
            logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ú©Ù„ÛŒÚ© XPath: {e}")
        
        # Ø±ÙˆØ´ 4: Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Load More
        try:
            load_more_selectors = [
                'button.load-more', '.load-more', '[class*="load-more"]',
                '.load-more-products', '.ajax-load-more',
                'button:contains("Load more")', 'button:contains("Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¨ÛŒØ´ØªØ±")'
            ]
            
            for selector in load_more_selectors:
                try:
                    buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for button in buttons:
                        try:
                            if button.is_displayed() and button.is_enabled():
                                logging.info(f"ğŸ”„ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Load More: {selector}")
                                self.driver.execute_script("arguments[0].click();", button)
                                time.sleep(4)  # Ø²Ù…Ø§Ù† Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ù„ÙˆØ¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯
                                return True
                        except:
                            continue
                except:
                    continue
        except Exception as e:
            logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ú©Ù„ÛŒÚ© Load More: {e}")
        
        logging.warning("âŒ Ù†ØªÙˆØ§Ù†Ø³Øª Ø±ÙˆÛŒ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ Ú©Ù„ÛŒÚ© Ú©Ù†Ø¯")
        return False
        
    def get_current_page_number(self, url):
            """Ø¯Ø±ÛŒØ§ÙØª Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡ ÙØ¹Ù„ÛŒ Ø§Ø² URL - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
            try:
                patterns = [
                    r'/page/(\d+)/',
                    r'[?&]page=(\d+)',
                    r'/product-page/(\d+)/',
                    r'[?&]paged=(\d+)',
                    r'/page-(\d+)/',
                    r'/page(\d+)/'
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, url)
                    if match:
                        page_num = int(match.group(1))
                        logging.info(f"ğŸ“– Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡ ÙØ¹Ù„ÛŒ: {page_num}")
                        return page_num
                
                # Ø§Ú¯Ø± Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ØµÙØ­Ù‡ Ø§ÙˆÙ„ Ø§Ø³Øª
                return 1
            except:
                return 1
    
    def scrape_products_from_page(self, category_name, site_id):
        """Ø§Ø³Ú©Ø±Ù¾ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ ÙÛŒÙ„ØªØ± ØªÚ©Ø±Ø§Ø±ÛŒ"""
        products = []
        config = self.site_configs[site_id]
        
        for selector in config['product_selectors']:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    logging.info(f"ğŸ¯ {len(elements)} Ø§Ù„Ù…Ù†Øª Ø¨Ø§ {selector}")
                    
                    for element in elements:
                        try:
                            if not self.is_running:
                                break
                                
                            product = self.extract_product_data(element, category_name, site_id)
                            if product and self.is_valid_product(product):
                                # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù† Ø¯Ø± Ù‡Ù…ÛŒÙ† ØµÙØ­Ù‡
                                if not any(p['name'] == product['name'] and p['price'] == product['price'] 
                                        for p in products):
                                    products.append(product)
                        except Exception as e:
                            continue
                    
                    if products:
                        break
            except:
                continue
        
        return products
    
    def is_duplicate_product(self, new_product, existing_products):
        """Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù† Ù…Ø­ØµÙˆÙ„"""
        for existing in existing_products:
            if (existing['name'] == new_product['name'] and 
                existing['price'] == new_product['price'] and
                existing['site'] == new_product['site']):
                return True
        return False
    
    def extract_product_data(self, element, category_name, site_id):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        try:
            full_text = element.text.strip()
            if len(full_text) < 10:  # Ú©Ø§Ù‡Ø´ Ø­Ø¯Ø§Ù‚Ù„ Ø·ÙˆÙ„ Ù…ØªÙ†
                return None
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù…
            name = self.extract_product_name(element, site_id)
            if not name or len(name) < 2:  # Ú©Ø§Ù‡Ø´ Ø­Ø¯Ø§Ù‚Ù„ Ø·ÙˆÙ„ Ù†Ø§Ù…
                lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                name = lines[0] if lines else "Ù…Ø­ØµÙˆÙ„ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡"
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª
            price = self.extract_product_price(element, site_id)
            if not price:
                price = self.extract_price_from_text(full_text)
            
            if not price:
                return None
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ URL
            url = self.extract_product_url(element, site_id)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ SKU
            sku = self.extract_sku(element, full_text, site_id)
            
            product_data = {
                'name': name[:200],  # Ø§ÙØ²Ø§ÛŒØ´ Ø·ÙˆÙ„ Ù†Ø§Ù…
                'price': price,
                'categories': category_name,
                'site': self.site_configs[site_id]['name'],
                'site_id': site_id,
                'type': 'product',
                'variation': 'standard',
                'sku': sku,
                'description': full_text[:300],  # Ø§ÙØ²Ø§ÛŒØ´ Ø·ÙˆÙ„ ØªÙˆØ¶ÛŒØ­Ø§Øª
                'url': url,
                'grouped_products': '',
                'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return product_data
            
        except Exception as e:
            logging.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„: {e}")
            return None
    
    def extract_product_name(self, element, site_id):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„ - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        config = self.site_configs[site_id]
        
        for selector in config['name_selectors']:
            try:
                if selector in ['h2', 'h3', 'h4', 'b', 'strong']:
                    # Ø§Ú¯Ø± Ø³Ù„Ú©ØªÙˆØ± ØªÚ¯ HTML Ø§Ø³Øª
                    if element.tag_name == selector:
                        name = element.text.strip()
                        if name and len(name) > 1:
                            return name
                    # ÛŒØ§ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¯Ø± ÙØ±Ø²Ù†Ø¯Ø§Ù†
                    try:
                        name_elems = element.find_elements(By.TAG_NAME, selector)
                        for name_elem in name_elems:
                            name = name_elem.text.strip()
                            if name and len(name) > 1:
                                return name
                    except:
                        continue
                else:
                    # Ø³Ù„Ú©ØªÙˆØ± CSS Ù…Ø¹Ù…ÙˆÙ„ÛŒ
                    name_elems = element.find_elements(By.CSS_SELECTOR, selector)
                    for name_elem in name_elems:
                        name = name_elem.text.strip()
                        if name and len(name) > 1:
                            return name
            except:
                continue
        
        return None
    
    def extract_product_price(self, element, site_id):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ù…Ø­ØµÙˆÙ„ - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        config = self.site_configs[site_id]
        
        for selector in config['price_selectors']:
            try:
                price_elems = element.find_elements(By.CSS_SELECTOR, selector)
                for price_elem in price_elems:
                    try:
                        price_text = price_elem.text.strip()
                        price = self.extract_price_from_text(price_text)
                        if price:
                            return price
                    except:
                        continue
            except:
                continue
        
        return None
    
    def extract_price_from_text(self, text):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø§Ø² Ù…ØªÙ† - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        try:
            # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ùˆ Ø­ÙØ¸ Ø§Ø¹Ø¯Ø§Ø¯ Ùˆ Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡â€ŒÙ‡Ø§
            clean_text = re.sub(r'[^\d,\.\s]', '', text.strip())
            clean_text = re.sub(r'\s+', ' ', clean_text)
            
            # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù‚ÛŒÙ…Øª
            patterns = [
                r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?)',  # ÙØ±Ù…Øª 1,000,000
                r'(\d{1,3}(?:\.\d{3})*(?:,\d+)?)',  # ÙØ±Ù…Øª 1.000.000
                r'(\d+)'  # ÙÙ‚Ø· Ø§Ø¹Ø¯Ø§Ø¯
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, clean_text)
                for match in matches:
                    try:
                        # Ø­Ø°Ù Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¹Ø¯Ø¯
                        price_str = re.sub(r'[^\d]', '', match)
                        if price_str.isdigit():
                            price = int(price_str)
                            # Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ù†Ø·Ù‚ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÛŒÙ¾
                            if 1000 <= price <= 50000000:
                                return str(price)
                    except:
                        continue
        except:
            pass
        
        return None
    
    def extract_product_url(self, element, site_id):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ URL Ù…Ø­ØµÙˆÙ„"""
        try:
            # Ø§Ú¯Ø± Ø®ÙˆØ¯ Ø§Ù„Ù…Ù†Øª Ù„ÛŒÙ†Ú© Ø§Ø³Øª
            if element.tag_name == 'a':
                href = element.get_attribute('href')
                if href and 'http' in href:
                    return href
            
            # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú© Ø¯Ø± ÙØ±Ø²Ù†Ø¯Ø§Ù†
            links = element.find_elements(By.TAG_NAME, 'a')
            for link in links:
                href = link.get_attribute('href')
                if href and 'http' in href:
                    return href
            
            return ""
        except:
            return ""
    
    def extract_sku(self, element, text, site_id):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ SKU Ù…Ø­ØµÙˆÙ„"""
        try:
            sku_patterns = [
                r'SKU:\s*([A-Za-z0-9-]+)',
                r'Ú©Ø¯:\s*([A-Za-z0-9-]+)',
                r'Ø´Ù†Ø§Ø³Ù‡:\s*([A-Za-z0-9-]+)',
                r'([A-Z]{2,3}\d{3,})',
                r'Ú©Ø¯ Ù…Ø­ØµÙˆÙ„:\s*([^\s]+)'
            ]
            
            for pattern in sku_patterns:
                matches = re.findall(pattern, text)
                if matches:
                    return matches[0]
        except:
            pass
        
        return ""
    
    def is_valid_product(self, product):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ù…Ø­ØµÙˆÙ„ - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        if not product.get('name') or len(product['name']) < 2:
            return False
        
        if not product.get('price') or not product['price'].isdigit():
            return False
        
        price_num = int(product['price'])
        if price_num < 500 or price_num > 100000000:  # Ú¯Ø³ØªØ±Ø´ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù‚ÛŒÙ…Øª
            return False
        
        return True
    
    def alternative_scraping_methods(self, category_name, site_id):
        """Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        products = []
        
        try:
            # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ù„Ù…Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙˆÛŒ Ù‚ÛŒÙ…Øª
            price_indicators = ['ØªÙˆÙ…Ø§Ù†', 'Ø±ÛŒØ§Ù„', 'price', 'Ù‚ÛŒÙ…Øª', 'Ø®Ø±ÛŒØ¯']
            for indicator in price_indicators:
                try:
                    elements = self.driver.find_elements(By.XPATH, f'//*[contains(text(), "{indicator}")]')
                    for element in elements[:50]:  # Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ù†Øªâ€ŒÙ‡Ø§
                        try:
                            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙˆØ§Ù„Ø¯ Ú©Ù‡ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ Ø§Ø³Øª
                            parent = element.find_element(By.XPATH, './ancestor::*[position()<5]')
                            text = parent.text.strip()
                            if len(text) > 30 and self.looks_like_product(text):
                                product = self.create_product_from_text(text, category_name, site_id)
                                if product and self.is_valid_product(product) and not self.is_duplicate_product(product, products):
                                    products.append(product)
                        except:
                            continue
                except:
                    continue
        except:
            pass
        
        return products
    
    def create_product_from_text(self, text, category_name, site_id):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„ Ø§Ø² Ù…ØªÙ†"""
        try:
            lines = [line.strip() for line in text.split('\n') if line.strip() and len(line.strip()) > 2]
            if not lines:
                return None
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… (Ø§ÙˆÙ„ÛŒÙ† Ø®Ø· Ù…Ø¹Ù‚ÙˆÙ„)
            name = lines[0]
            for line in lines:
                if len(line) > 5 and not any(indicator in line.lower() for indicator in ['ØªÙˆÙ…Ø§Ù†', 'Ø±ÛŒØ§Ù„', 'Ù‚ÛŒÙ…Øª', 'price', 'Ø®Ø±ÛŒØ¯']):
                    name = line
                    break
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª
            price = self.extract_price_from_text(text)
            if not price:
                return None
            
            return {
                'name': name[:200],
                'price': price,
                'categories': category_name,
                'site': self.site_configs[site_id]['name'],
                'site_id': site_id,
                'type': 'product',
                'variation': 'standard',
                'sku': '',
                'description': text[:300],
                'url': '',
                'grouped_products': '',
                'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        except:
            return None
    
    def looks_like_product(self, text):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù…ØªÙ† Ø´Ø¨ÛŒÙ‡ Ù…Ø­ØµÙˆÙ„ Ø§Ø³Øª - **Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡**"""
        must_have = ['ØªÙˆÙ…Ø§Ù†', 'Ø±ÛŒØ§Ù„', 'price']
        nice_to_have = ['Ù‚ÛŒÙ…Øª', 'Ø®Ø±ÛŒØ¯', 'Ø¬ÙˆÛŒØ³', 'Ù¾Ø§Ø¯', 'ÙˆÛŒÙ¾', 'Ú©ÙˆÛŒÙ„', 'Ø³ÛŒØ³ØªÙ…', 'Ù…Ø­ØµÙˆÙ„', 'product', 'vape']
        
        text_lower = text.lower()
        
        if not any(indicator in text_lower for indicator in must_have):
            return False
        
        if any(indicator in text_lower for indicator in nice_to_have):
            return True
        
        return len(text) > 50  # Ú©Ø§Ù‡Ø´ Ø­Ø¯Ø§Ù‚Ù„ Ø·ÙˆÙ„
    
    def scrape_all_sites(self):
        """Ø§Ø³Ú©Ø±Ù¾ ØªÙ…Ø§Ù… 7 Ø³Ø§ÛŒØª Ù‡Ø¯Ù"""
        target_sites = [
            "https://vape60shop22.com",
            "https://tajvape12.com", 
            "https://vapoursdaily14.com",
            "https://digizima19.com",
            "https://smokcenter16.com",
            "https://digighelioon.com",
            "https://dokhanmarket3.com"
        ]
        
        return self.scrape_multiple_sites(target_sites)
    
    def scrape_multiple_sites(self, site_urls):
        """Ø§Ø³Ú©Ø±Ù¾ Ú†Ù†Ø¯ÛŒÙ† Ø³Ø§ÛŒØª - **Ø§ØµÙ„Ø§Ø­ Ù†Ù‡Ø§ÛŒÛŒ**"""
        self.is_running = True
        total_results = []
        
        try:
            for i, site_url in enumerate(site_urls, 1):
                if not self.is_running:
                    break
                
                logging.info(f"ğŸŒ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±Ù¾ Ø³Ø§ÛŒØª {i}/{len(site_urls)}: {site_url}")
                self.update_status(f"Ø³Ø§ÛŒØª {i}", current_site=site_url)
                
                # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø§ÛŒØª
                site_id = self.identify_site(site_url)
                self.current_site = site_id
                
                # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
                categories = self.get_categories(site_url, site_id)
                logging.info(f"ğŸ“‚ {len(categories)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ {site_id} ÛŒØ§ÙØª Ø´Ø¯")
                
                site_products = []
                
                # Ø§Ø³Ú©Ø±Ù¾ Ù‡Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
                for j, category in enumerate(categories, 1):
                    if not self.is_running:
                        break
                    
                    logging.info(f"ğŸ”„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {j}/{len(categories)}: {category['name']}")
                    
                    # **Ø§ØµÙ„Ø§Ø­ Ø§ØµÙ„ÛŒ: Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¬Ø¯ÛŒØ¯**
                    try:
                        self.driver.get(site_url)  # Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ
                        time.sleep(2)
                    except:
                        pass
                    
                    # Ø§Ø³Ú©Ø±Ù¾ ØªÙ…Ø§Ù… ØµÙØ­Ø§Øª Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
                    category_products = self.scrape_category_pages(
                        category['url'], 
                        category['name'], 
                        site_id
                    )
                    
                    if category_products:
                        site_products.extend(category_products)
                        logging.info(f"âœ… {len(category_products)} Ù…Ø­ØµÙˆÙ„ Ø§Ø² {category['name']}")
                    
                    time.sleep(2)  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
                    
                    # **Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ**
                    self.products_data.extend(site_products)
                    self.save_progress()
                    
                    # **Ø¢Ù¾Ø¯ÛŒØª ÙˆØ¶Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† Ù¾ÛŒØ´Ø±ÙØª**
                    self.update_status(
                        f"Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {j}/{len(categories)} Ø§Ø² Ø³Ø§ÛŒØª {i}", 
                        current_site=site_id
                    )
                
                # **Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒÙ† Ø³Ø§ÛŒØª**
                if site_products:
                    total_results.append({
                        'site': site_id,
                        'site_name': self.site_configs[site_id]['name'],
                        'url': site_url,
                        'categories_count': len(categories),
                        'products_count': len(site_products),
                        'status': 'success'
                    })
                    
                    logging.info(f"âœ… Ø§ØªÙ…Ø§Ù… Ø³Ø§ÛŒØª {site_id}: {len(site_products)} Ù…Ø­ØµÙˆÙ„")
                else:
                    logging.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ Ø§Ø² Ø³Ø§ÛŒØª {site_id} ÛŒØ§ÙØª Ù†Ø´Ø¯")
                
                time.sleep(3)  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§
            
            # **Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ù‡Ù…Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª**
            excel_file = self.save_to_excel()
            
            final_result = {
                'success': True,
                'job_id': self.job_id,
                'total_products': len(self.products_data),
                'sites_scraped': len(total_results),
                'excel_file': excel_file,
                'site_results': total_results,
                'message': f'ØªØ¹Ø¯Ø§Ø¯ {len(self.products_data)} Ù…Ø­ØµÙˆÙ„ Ø§Ø² {len(total_results)} Ø³Ø§ÛŒØª ÛŒØ§ÙØª Ø´Ø¯'
            }
            
            logging.info(f"ğŸ‰ Ø§ØªÙ…Ø§Ù… Ú©Ø§Ù…Ù„ Ø§Ø³Ú©Ø±Ù¾: {final_result}")
            return final_result
            
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§: {str(e)}"
            logging.error(f"âŒ {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'job_id': self.job_id
            }
        finally:
            self.is_running = False
    
    def save_progress(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ´Ø±ÙØª"""
        try:
            progress_data = {
                'job_id': self.job_id,
                'products': self.products_data,
                'total_products': len(self.products_data),
                'current_site': self.current_site,
                'timestamp': datetime.now().isoformat()
            }
            
            with open(f'tmp_jobs/{self.job_id}.json', 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ´Ø±ÙØª: {e}")
    
    def save_to_excel(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø§Ú©Ø³Ù„ Ø¨Ø§ Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ - **Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ**"""
        if not self.products_data:
            logging.warning("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return None
        
        try:
            filename = f"tmp_jobs/{self.job_id}.xlsx"
            
            # Ø§ÛŒØ¬Ø§Ø¯ DataFrame Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            df = pd.DataFrame(self.products_data)
            
            # **Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡**
            initial_count = len(df)
            
            # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù…ØŒ Ù‚ÛŒÙ…Øª Ùˆ Ø³Ø§ÛŒØª
            df = df.drop_duplicates(
                subset=['name', 'price', 'site'], 
                keep='first'
            )
            
            # Ù‡Ù…Ú†Ù†ÛŒÙ† Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ (Ù‡Ù…Ù‡ ÙÛŒÙ„Ø¯Ù‡Ø§)
            df = df.drop_duplicates(keep='first')
            
            final_count = len(df)
            duplicates_removed = initial_count - final_count
            
            logging.info(f"ğŸ§¹ Ø­Ø°Ù {duplicates_removed} Ù…ÙˆØ±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø² {initial_count} Ù…Ø­ØµÙˆÙ„")
            
            # Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù†Ø¯
            if len(df) == 0:
                logging.warning("âš ï¸ Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù†Ø¯ - Ø°Ø®ÛŒØ±Ù‡ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø±Ú©ÙˆØ±Ø¯")
                # Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø±
                df = pd.DataFrame(self.products_data[:1])
            
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ
            wb = Workbook()
            ws = wb.active
            ws.title = "Products"
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù‡Ø¯Ø±Ù‡Ø§
            headers = list(df.columns)
            ws.append(headers)
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ØªÚ©Ø±Ø§Ø±ÛŒ
            for _, row in df.iterrows():
                ws.append(row.tolist())
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù…Ø§Ø±ÛŒ Ø¯Ø± ÛŒÚ© sheet Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            stats_sheet = wb.create_sheet(title="Ø¢Ù…Ø§Ø±")
            stats_data = [
                ["Ø¢Ù…Ø§Ø± Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡"],
                ["ØªØ§Ø±ÛŒØ® Ø§Ø³ØªØ®Ø±Ø§Ø¬", datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
                ["ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡", initial_count],
                ["ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯", final_count],
                ["ØªØ¹Ø¯Ø§Ø¯ Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡", duplicates_removed],
                ["ØªØ¹Ø¯Ø§Ø¯ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§", len(df['site'].unique())],
                [],
                ["ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù‡Ø± Ø³Ø§ÛŒØª:"]
            ]
            
            # Ø¢Ù…Ø§Ø± Ù‡Ø± Ø³Ø§ÛŒØª
            site_stats = df['site'].value_counts()
            for site, count in site_stats.items():
                stats_data.append([site, count])
            
            for row in stats_data:
                stats_sheet.append(row)
            
            # ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ
            self.apply_excel_styling(ws, len(df))
            
            # ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ sheet Ø¢Ù…Ø§Ø±
            try:
                for col in range(1, 3):
                    stats_sheet.column_dimensions[get_column_letter(col)].width = 30
                
                for row in range(1, len(stats_data) + 1):
                    for col in range(1, 3):
                        cell = stats_sheet.cell(row=row, column=col)
                        if row == 1:
                            cell.font = Font(bold=True, size=14, color="1565C0")
                        elif row <= 7:
                            cell.font = Font(bold=True, color="2E7D32")
            except:
                pass
            
            # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
            wb.save(filename)
            logging.info(f"ğŸ’¾ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename} (Ø¨Ø§ {final_count} Ù…Ø­ØµÙˆÙ„ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯)")
            
            # Ù‡Ù…Ú†Ù†ÛŒÙ† ÛŒÚ© ÙØ§ÛŒÙ„ JSON Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ØªÚ©Ø±Ø§Ø±ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
            unique_data = {
                'job_id': self.job_id,
                'total_products_initial': initial_count,
                'total_products_final': final_count,
                'duplicates_removed': duplicates_removed,
                'products': df.to_dict('records'),
                'timestamp': datetime.now().isoformat()
            }
            
            with open(f'tmp_jobs/{self.job_id}_unique.json', 'w', encoding='utf-8') as f:
                json.dump(unique_data, f, ensure_ascii=False, indent=2)
            
            return filename
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ú©Ø³Ù„: {e}")
            # Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø¯Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
            try:
                simple_filename = f"tmp_jobs/{self.job_id}_simple.xlsx"
                df = pd.DataFrame(self.products_data)
                df.to_excel(simple_filename, index=False, engine='openpyxl')
                return simple_filename
            except Exception as e2:
                logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø¯Ù‡: {e2}")
                return None
    
    def apply_excel_styling(self, worksheet, data_count):
        """Ø§Ø¹Ù…Ø§Ù„ Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ¨Ø§ Ø¨Ù‡ Ø§Ú©Ø³Ù„"""
        try:
            # Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù„Ø§ÛŒÙ… Ùˆ Ú†Ø´Ù…â€ŒÙ†ÙˆØ§Ø²
            header_fill = PatternFill(start_color="18AAC4", end_color="18AAC4", fill_type="solid")  # Ø¢Ø¨ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù…Ù„Ø§ÛŒÙ…
            even_row_fill = PatternFill(start_color="C2F0FF", end_color="C2F0FF", fill_type="solid")  # Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù…Ù„Ø§ÛŒÙ…
            odd_row_fill = PatternFill(start_color="FFFFFF", end_color="FFFFFF", fill_type="solid")   # Ø³ÙÛŒØ¯
            price_fill = PatternFill(start_color="F0F8EB", end_color="F0F8EB", fill_type="solid")     # Ø³Ø¨Ø² Ø¨Ø³ÛŒØ§Ø± Ù…Ù„Ø§ÛŒÙ…
            site_fill = PatternFill(start_color="F0F8EB", end_color="F0F8EB", fill_type="solid")      # Ù†Ø§Ø±Ù†Ø¬ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù…Ù„Ø§ÛŒÙ…
            
            # ÙÙˆÙ†Øªâ€ŒÙ‡Ø§
            header_font = Font(bold=True, color="2E4057", size=11)
            normal_font = Font(color="2D2D2D", size=10)
            price_font = Font(bold=True, color="2E8B57", size=10)
            site_font = Font(bold=True, color="2E4057", size=10)
            
            # ØªØ±Ø§Ø²
            center_align = Alignment(horizontal='center', vertical='center')
            right_align = Alignment(horizontal='right', vertical='center')
            left_align = Alignment(horizontal='left', vertical='center')
            
            # ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ù‡Ø¯Ø±
            for col in range(1, len(worksheet[1]) + 1):
                cell = worksheet.cell(row=1, column=col)
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = center_align
            
            # ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            for row in range(2, data_count + 2):
                # Ø±Ù†Ú¯â€ŒØ¢Ù…ÛŒØ²ÛŒ Ø³Ø·Ø±Ù‡Ø§ ÛŒÚ©ÛŒ Ø¯Ø± Ù…ÛŒØ§Ù†
                if row % 2 == 0:
                    row_fill = even_row_fill
                else:
                    row_fill = odd_row_fill
                
                for col in range(1, len(worksheet[1]) + 1):
                    cell = worksheet.cell(row=row, column=col)
                    cell.font = normal_font
                    cell.fill = row_fill
                    
                    header_value = worksheet.cell(row=1, column=col).value
                    
                    # ÙØ±Ù…Øª Ù…Ø®ØµÙˆØµ Ù‚ÛŒÙ…Øª
                    if header_value == 'price':
                        cell.font = price_font
                        cell.fill = price_fill
                        cell.alignment = right_align
                    # ÙØ±Ù…Øª Ù…Ø®ØµÙˆØµ Ø³Ø§ÛŒØª
                    elif header_value in ['site', 'site_id']:
                        cell.font = site_font
                        cell.fill = site_fill
                        cell.alignment = center_align
                    # ÙØ±Ù…Øª Ù…Ø®ØµÙˆØµ Ù†Ø§Ù…
                    elif header_value == 'name':
                        cell.alignment = left_align
                    else:
                        cell.alignment = right_align
            
            # ØªÙ†Ø¸ÛŒÙ… Ø¹Ø±Ø¶ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            column_widths = {
                'name': 80,
                'price': 15,
                'categories': 25,
                'site': 20,
                'site_id': 15,
                'description': 130,
                'url': 50
            }
            
            for col in range(1, len(worksheet[1]) + 1):
                header = worksheet.cell(row=1, column=col).value
                if header in column_widths:
                    worksheet.column_dimensions[get_column_letter(col)].width = column_widths[header]
                else:
                    worksheet.column_dimensions[get_column_letter(col)].width = 15
            
            # ÙØ±ÛŒØ² Ú©Ø±Ø¯Ù† Ù‡Ø¯Ø±
            worksheet.freeze_panes = "A2"
            
            logging.info("ğŸ¨ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø§Ú©Ø³Ù„ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯")
            
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹Ù…Ø§Ù„ Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§: {e}")
    
    def stop(self):
        """ØªÙˆÙ‚Ù Ø§Ø³Ú©Ø±Ù¾"""
        self.is_running = False
    
    def close(self):
        """Ø¨Ø³ØªÙ† Ø¯Ø±Ø§ÛŒÙˆØ±"""
        if self.driver:
            try:
                self.driver.quit()
                logging.info("ğŸ”š Ø¯Ø±Ø§ÛŒÙˆØ± Ø¨Ø³ØªÙ‡ Ø´Ø¯")
            except:
                pass

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§
def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾Ø±"""
    scraper = AdvancedVapeScraper()
    
    try:
        result = scraper.scrape_all_sites()
        print("Ù†ØªØ§ÛŒØ¬:", result)
        
        if result['success']:
            print(f"ğŸ‰ Ø§Ø³Ú©Ø±Ù¾ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
            print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {result['total_products']}")
            print(f"ğŸŒ ØªØ¹Ø¯Ø§Ø¯ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§: {result['sites_scraped']}")
            print(f"ğŸ’¾ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„: {result['excel_file']}")
        else:
            print(f"âŒ Ø®Ø·Ø§: {result['error']}")
            
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ: {e}")
    finally:
        scraper.close()

if __name__ == "__main__":
    main()